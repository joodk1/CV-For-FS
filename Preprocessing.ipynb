{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Statements Page Classification - Data Preprocessing\n",
    "\n",
    "## Overview\n",
    "This notebook preprocesses the financial statement pages for training three different computer vision models:\n",
    "\n",
    "1. **ResNet50** - Classic CNN with transfer learning (224x224)\n",
    "2. **EfficientNet-B2** - Modern efficient architecture (260x260)\n",
    "3. **Vision Transformer (ViT-Base)** - Transformer-based approach (224x224)\n",
    "\n",
    "### Dataset Statistics:\n",
    "- Total pages: 1,179\n",
    "- Average dimensions: 1277 x 1692 pixels\n",
    "- 5 Target Classes (with imbalance):\n",
    "  - Notes (Tabular): 557 (47.2%)\n",
    "  - Notes (Text): 321 (27.2%)\n",
    "  - Financial Sheets: 124 (10.5%)\n",
    "  - Independent Auditor's Report: 111 (9.4%)\n",
    "  - Other Pages: 66 (5.6%)\n",
    "\n",
    "### Remaining Preprocessing Steps:\n",
    "1. ~~Extract pages from PDFs~~ ‚úÖ Already done\n",
    "2. ~~Create labels~~ ‚úÖ Already done\n",
    "3. **Train/Val/Test split (stratified)**\n",
    "4. **Model-specific transformations**\n",
    "5. **Data augmentation**\n",
    "6. **Create PyTorch DataLoaders**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q torch torchvision\n",
    "!pip install -q timm  # For EfficientNet and ViT\n",
    "!pip install -q albumentations  # Advanced augmentations\n",
    "!pip install -q Pillow opencv-python-headless\n",
    "!pip install -q pandas numpy scikit-learn matplotlib seaborn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from typing import List, Dict, Tuple, Optional, Callable\n",
    "\n",
    "# Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# timm for modern architectures\n",
    "import timm\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Utilities\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Check device\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CONFIGURATION - UPDATE THESE PATHS\n",
    "# ============================================\n",
    "\n",
    "# Path to your extracted images folder\n",
    "IMAGES_DIR = \"/content/drive/MyDrive/YOUR_IMAGES_FOLDER\"  # <-- UPDATE THIS\n",
    "\n",
    "# Path to your labels CSV file\n",
    "LABELS_CSV_PATH = \"/content/drive/MyDrive/YOUR_LABELS.csv\"  # <-- UPDATE THIS\n",
    "\n",
    "# Output directory for processed data\n",
    "OUTPUT_DIR = \"/content/drive/MyDrive/FS_Classification_Processed\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'seed': 42,\n",
    "    'test_size': 0.15,\n",
    "    'val_size': 0.15,\n",
    "    'batch_size': 16,\n",
    "    'num_workers': 2,\n",
    "    'num_classes': 5,\n",
    "}\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "def set_seed(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(CONFIG['seed'])\n",
    "print(f\"Configuration: {CONFIG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load Your Existing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the labels CSV\n",
    "# Expected columns: image_path (or filename), label\n",
    "# Adjust column names below if different\n",
    "\n",
    "labels_df = pd.read_csv(LABELS_CSV_PATH)\n",
    "\n",
    "print(f\"Loaded {len(labels_df)} labeled samples\")\n",
    "print(f\"\\nColumns: {labels_df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "display(labels_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ADJUST COLUMN NAMES HERE IF NEEDED\n",
    "# ============================================\n",
    "\n",
    "# Column containing image filename or path\n",
    "IMAGE_COL = 'image_path'  # <-- UPDATE if different (e.g., 'filename', 'image_name')\n",
    "\n",
    "# Column containing label\n",
    "LABEL_COL = 'label'  # <-- UPDATE if different (e.g., 'class', 'category')\n",
    "\n",
    "# If your CSV only has filename (not full path), construct full path\n",
    "if not labels_df[IMAGE_COL].str.startswith('/').any():\n",
    "    labels_df['image_path_full'] = labels_df[IMAGE_COL].apply(lambda x: os.path.join(IMAGES_DIR, x))\n",
    "else:\n",
    "    labels_df['image_path_full'] = labels_df[IMAGE_COL]\n",
    "\n",
    "# Verify paths exist\n",
    "labels_df['exists'] = labels_df['image_path_full'].apply(os.path.exists)\n",
    "missing = labels_df[~labels_df['exists']]\n",
    "\n",
    "if len(missing) > 0:\n",
    "    print(f\"‚ö†Ô∏è WARNING: {len(missing)} images not found!\")\n",
    "    print(f\"Example missing: {missing['image_path_full'].iloc[0]}\")\n",
    "else:\n",
    "    print(f\"‚úÖ All {len(labels_df)} images found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only existing files\n",
    "df = labels_df[labels_df['exists']].copy()\n",
    "df = df.rename(columns={LABEL_COL: 'label', 'image_path_full': 'image_path'})\n",
    "\n",
    "print(f\"\\nWorking with {len(df)} samples\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "label_counts = df['label'].value_counts()\n",
    "colors = sns.color_palette('husl', len(label_counts))\n",
    "\n",
    "bars = plt.bar(range(len(label_counts)), label_counts.values, color=colors)\n",
    "plt.xticks(range(len(label_counts)), label_counts.index, rotation=45, ha='right')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Class Distribution (Imbalanced)', fontweight='bold')\n",
    "\n",
    "# Add count labels on bars\n",
    "for bar, count in zip(bars, label_counts.values):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5, \n",
    "             f'{count}\\n({count/len(df)*100:.1f}%)', ha='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate imbalance ratio\n",
    "max_class = label_counts.max()\n",
    "min_class = label_counts.min()\n",
    "print(f\"\\nImbalance ratio (max/min): {max_class/min_class:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class names in consistent order\n",
    "CLASS_NAMES = [\n",
    "    'Financial Sheets',\n",
    "    'Independent Auditor\\'s Report',\n",
    "    'Notes (Tabular)',\n",
    "    'Notes (Text)',\n",
    "    'Other Pages'\n",
    "]\n",
    "\n",
    "# Create label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(CLASS_NAMES)\n",
    "\n",
    "# Encode labels\n",
    "df['label_encoded'] = label_encoder.transform(df['label'])\n",
    "\n",
    "print(\"Label encoding:\")\n",
    "for i, name in enumerate(label_encoder.classes_):\n",
    "    count = (df['label_encoded'] == i).sum()\n",
    "    print(f\"  {i}: {name} ({count} samples)\")\n",
    "\n",
    "# Save label encoder\n",
    "with open(os.path.join(OUTPUT_DIR, 'label_encoder.pkl'), 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "print(f\"\\nLabel encoder saved to {OUTPUT_DIR}/label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Train/Validation/Test Split (Stratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stratified_split(df: pd.DataFrame, \n",
    "                            test_size: float = 0.15, \n",
    "                            val_size: float = 0.15, \n",
    "                            seed: int = 42) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Create stratified train/val/test splits preserving class distribution.\n",
    "    \n",
    "    Split ratios: 70% train, 15% val, 15% test\n",
    "    \"\"\"\n",
    "    # First split: train+val vs test\n",
    "    train_val_df, test_df = train_test_split(\n",
    "        df, \n",
    "        test_size=test_size, \n",
    "        stratify=df['label_encoded'],\n",
    "        random_state=seed\n",
    "    )\n",
    "    \n",
    "    # Second split: train vs val\n",
    "    actual_val_size = val_size / (1 - test_size)\n",
    "    train_df, val_df = train_test_split(\n",
    "        train_val_df,\n",
    "        test_size=actual_val_size,\n",
    "        stratify=train_val_df['label_encoded'],\n",
    "        random_state=seed\n",
    "    )\n",
    "    \n",
    "    return train_df.reset_index(drop=True), val_df.reset_index(drop=True), test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create splits\n",
    "train_df, val_df, test_df = create_stratified_split(\n",
    "    df, \n",
    "    test_size=CONFIG['test_size'],\n",
    "    val_size=CONFIG['val_size'],\n",
    "    seed=CONFIG['seed']\n",
    ")\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"DATASET SPLITS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nTrain: {len(train_df)} samples ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"Val:   {len(val_df)} samples ({len(val_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"Test:  {len(test_df)} samples ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"Total: {len(train_df) + len(val_df) + len(test_df)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify stratification\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for ax, (name, split_df) in zip(axes, [('Train', train_df), ('Val', val_df), ('Test', test_df)]):\n",
    "    counts = split_df['label'].value_counts()\n",
    "    percentages = counts / len(split_df) * 100\n",
    "    \n",
    "    bars = ax.bar(range(len(counts)), counts.values, color=sns.color_palette('husl', len(counts)))\n",
    "    ax.set_xticks(range(len(counts)))\n",
    "    ax.set_xticklabels([c[:15] + '...' if len(c) > 15 else c for c in counts.index], rotation=45, ha='right')\n",
    "    ax.set_title(f'{name} Set (n={len(split_df)})', fontweight='bold')\n",
    "    ax.set_ylabel('Count')\n",
    "    \n",
    "    # Add percentage labels\n",
    "    for bar, pct in zip(bars, percentages.values):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2, \n",
    "                f'{pct:.1f}%', ha='center', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Stratification verified - class proportions maintained across splits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save splits\n",
    "train_df.to_csv(os.path.join(OUTPUT_DIR, 'train.csv'), index=False)\n",
    "val_df.to_csv(os.path.join(OUTPUT_DIR, 'val.csv'), index=False)\n",
    "test_df.to_csv(os.path.join(OUTPUT_DIR, 'test.csv'), index=False)\n",
    "\n",
    "print(f\"Splits saved to {OUTPUT_DIR}/\")\n",
    "print(f\"  - train.csv ({len(train_df)} samples)\")\n",
    "print(f\"  - val.csv ({len(val_df)} samples)\")\n",
    "print(f\"  - test.csv ({len(test_df)} samples)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Model-Specific Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet normalization values\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Model configurations\n",
    "MODEL_CONFIGS = {\n",
    "    'resnet50': {\n",
    "        'input_size': 224,\n",
    "        'mean': IMAGENET_MEAN,\n",
    "        'std': IMAGENET_STD,\n",
    "        'timm_name': 'resnet50',\n",
    "    },\n",
    "    'efficientnet_b2': {\n",
    "        'input_size': 260,\n",
    "        'mean': IMAGENET_MEAN,\n",
    "        'std': IMAGENET_STD,\n",
    "        'timm_name': 'efficientnet_b2',\n",
    "    },\n",
    "    'vit_base': {\n",
    "        'input_size': 224,\n",
    "        'mean': IMAGENET_MEAN,\n",
    "        'std': IMAGENET_STD,\n",
    "        'timm_name': 'vit_base_patch16_224',\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Model configurations:\")\n",
    "for name, config in MODEL_CONFIGS.items():\n",
    "    print(f\"  {name}: {config['input_size']}x{config['input_size']} input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_transforms(input_size: int, mean: List[float], std: List[float]) -> A.Compose:\n",
    "    \"\"\"\n",
    "    Training augmentation pipeline using Albumentations.\n",
    "    Designed for document images (conservative augmentations).\n",
    "    \"\"\"\n",
    "    return A.Compose([\n",
    "        # Resize maintaining aspect ratio, then pad and crop\n",
    "        A.LongestMaxSize(max_size=int(input_size * 1.15)),\n",
    "        A.PadIfNeeded(\n",
    "            min_height=int(input_size * 1.15), \n",
    "            min_width=int(input_size * 1.15),\n",
    "            border_mode=cv2.BORDER_CONSTANT,\n",
    "            value=(255, 255, 255)  # White padding for documents\n",
    "        ),\n",
    "        A.RandomCrop(height=input_size, width=input_size),\n",
    "        \n",
    "        # Geometric augmentations (subtle for documents)\n",
    "        A.ShiftScaleRotate(\n",
    "            shift_limit=0.05,\n",
    "            scale_limit=0.1,\n",
    "            rotate_limit=5,\n",
    "            border_mode=cv2.BORDER_CONSTANT,\n",
    "            value=(255, 255, 255),\n",
    "            p=0.5\n",
    "        ),\n",
    "        A.Perspective(scale=(0.02, 0.05), p=0.3),\n",
    "        \n",
    "        # Quality augmentations\n",
    "        A.OneOf([\n",
    "            A.GaussianBlur(blur_limit=(3, 5), p=1.0),\n",
    "            A.MotionBlur(blur_limit=3, p=1.0),\n",
    "        ], p=0.2),\n",
    "        \n",
    "        A.ImageCompression(quality_lower=75, quality_upper=100, p=0.3),\n",
    "        A.GaussNoise(var_limit=(5.0, 20.0), p=0.2),\n",
    "        \n",
    "        # Slight contrast/brightness variation\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3),\n",
    "        \n",
    "        # Normalize and convert to tensor\n",
    "        A.Normalize(mean=mean, std=std),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_val_transforms(input_size: int, mean: List[float], std: List[float]) -> A.Compose:\n",
    "    \"\"\"\n",
    "    Validation/test transform pipeline - no augmentation.\n",
    "    \"\"\"\n",
    "    return A.Compose([\n",
    "        A.LongestMaxSize(max_size=input_size),\n",
    "        A.PadIfNeeded(\n",
    "            min_height=input_size, \n",
    "            min_width=input_size,\n",
    "            border_mode=cv2.BORDER_CONSTANT,\n",
    "            value=(255, 255, 255)\n",
    "        ),\n",
    "        A.CenterCrop(height=input_size, width=input_size),\n",
    "        A.Normalize(mean=mean, std=std),\n",
    "        ToTensorV2()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize augmentations\n",
    "def visualize_augmentations(image_path: str, transform: A.Compose, n_samples: int = 6):\n",
    "    \"\"\"Show multiple augmented versions of an image.\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, (n_samples + 1) // 2, figsize=(15, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Original (resized for display)\n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title('Original', fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Augmented versions\n",
    "    for i in range(1, n_samples):\n",
    "        augmented = transform(image=img)['image']\n",
    "        aug_img = augmented.permute(1, 2, 0).numpy()\n",
    "        aug_img = aug_img * np.array(IMAGENET_STD) + np.array(IMAGENET_MEAN)\n",
    "        aug_img = np.clip(aug_img, 0, 1)\n",
    "        \n",
    "        axes[i].imshow(aug_img)\n",
    "        axes[i].set_title(f'Augmented {i}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Data Augmentation Examples', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show augmentation examples\n",
    "sample_image = train_df.iloc[0]['image_path']\n",
    "sample_transform = get_train_transforms(224, IMAGENET_MEAN, IMAGENET_STD)\n",
    "visualize_augmentations(sample_image, sample_transform, n_samples=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. PyTorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinancialStatementDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for Financial Statement page classification.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe: pd.DataFrame, transform: Optional[Callable] = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe: DataFrame with 'image_path' and 'label_encoded' columns\n",
    "            transform: Albumentations transform pipeline\n",
    "        \"\"\"\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image = cv2.imread(row['image_path'])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Get label\n",
    "        label = row['label_encoded']\n",
    "        \n",
    "        # Apply transform\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image)\n",
    "            image = transformed['image']\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def get_labels(self) -> np.ndarray:\n",
    "        \"\"\"Return all labels (for weighted sampler).\"\"\"\n",
    "        return self.df['label_encoded'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Handle Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weighted_sampler(dataset: FinancialStatementDataset) -> WeightedRandomSampler:\n",
    "    \"\"\"\n",
    "    Create weighted sampler for handling class imbalance.\n",
    "    Over-samples minority classes during training.\n",
    "    \"\"\"\n",
    "    labels = dataset.get_labels()\n",
    "    class_counts = Counter(labels)\n",
    "    \n",
    "    # Calculate weights (inverse frequency)\n",
    "    total_samples = len(labels)\n",
    "    class_weights = {cls: total_samples / count for cls, count in class_counts.items()}\n",
    "    \n",
    "    # Assign weight to each sample\n",
    "    sample_weights = [class_weights[label] for label in labels]\n",
    "    \n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "    \n",
    "    print(\"Class weights for sampling:\")\n",
    "    for cls, weight in sorted(class_weights.items()):\n",
    "        print(f\"  Class {cls} ({label_encoder.classes_[cls][:20]}): {weight:.3f}\")\n",
    "    \n",
    "    return sampler\n",
    "\n",
    "\n",
    "def compute_class_weights(train_df: pd.DataFrame, num_classes: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute class weights for weighted loss function.\n",
    "    \"\"\"\n",
    "    class_counts = train_df['label_encoded'].value_counts().sort_index()\n",
    "    total_samples = len(train_df)\n",
    "    \n",
    "    # Inverse frequency weighting\n",
    "    weights = total_samples / (num_classes * class_counts.values)\n",
    "    weights = weights / weights.sum() * num_classes  # Normalize\n",
    "    \n",
    "    return torch.FloatTensor(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and save class weights\n",
    "class_weights = compute_class_weights(train_df, CONFIG['num_classes'])\n",
    "\n",
    "print(\"\\nClass weights for loss function:\")\n",
    "for i, (name, weight) in enumerate(zip(label_encoder.classes_, class_weights)):\n",
    "    print(f\"  {i}: {name}: {weight:.4f}\")\n",
    "\n",
    "# Save class weights\n",
    "torch.save(class_weights, os.path.join(OUTPUT_DIR, 'class_weights.pt'))\n",
    "print(f\"\\nClass weights saved to {OUTPUT_DIR}/class_weights.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(train_df: pd.DataFrame, \n",
    "                       val_df: pd.DataFrame, \n",
    "                       test_df: pd.DataFrame,\n",
    "                       model_name: str,\n",
    "                       batch_size: int = 16,\n",
    "                       num_workers: int = 2,\n",
    "                       use_weighted_sampling: bool = True) -> Dict[str, DataLoader]:\n",
    "    \"\"\"\n",
    "    Create DataLoaders for a specific model configuration.\n",
    "    \"\"\"\n",
    "    config = MODEL_CONFIGS[model_name]\n",
    "    input_size = config['input_size']\n",
    "    mean = config['mean']\n",
    "    std = config['std']\n",
    "    \n",
    "    # Create transforms\n",
    "    train_transform = get_train_transforms(input_size, mean, std)\n",
    "    val_transform = get_val_transforms(input_size, mean, std)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = FinancialStatementDataset(train_df, train_transform)\n",
    "    val_dataset = FinancialStatementDataset(val_df, val_transform)\n",
    "    test_dataset = FinancialStatementDataset(test_df, val_transform)\n",
    "    \n",
    "    # Setup sampler for imbalanced data\n",
    "    train_sampler = None\n",
    "    shuffle_train = True\n",
    "    \n",
    "    if use_weighted_sampling:\n",
    "        print(f\"\\nCreating weighted sampler for {model_name}...\")\n",
    "        train_sampler = get_weighted_sampler(train_dataset)\n",
    "        shuffle_train = False\n",
    "    \n",
    "    # Create dataloaders\n",
    "    dataloaders = {\n",
    "        'train': DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle_train,\n",
    "            sampler=train_sampler,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=True\n",
    "        ),\n",
    "        'val': DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True\n",
    "        ),\n",
    "        'test': DataLoader(\n",
    "            test_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{model_name.upper()} DataLoaders:\")\n",
    "    print(f\"  Input size: {input_size}x{input_size}\")\n",
    "    print(f\"  Train batches: {len(dataloaders['train'])}\")\n",
    "    print(f\"  Val batches: {len(dataloaders['val'])}\")\n",
    "    print(f\"  Test batches: {len(dataloaders['test'])}\")\n",
    "    \n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders for all three models\n",
    "print(\"=\"*60)\n",
    "print(\"CREATING DATALOADERS FOR ALL MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_dataloaders = {}\n",
    "\n",
    "for model_name in MODEL_CONFIGS.keys():\n",
    "    print(f\"\\n{'-'*40}\")\n",
    "    all_dataloaders[model_name] = create_dataloaders(\n",
    "        train_df, val_df, test_df,\n",
    "        model_name=model_name,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        num_workers=CONFIG['num_workers'],\n",
    "        use_weighted_sampling=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Verify DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_batch(dataloader: DataLoader, model_name: str, n_samples: int = 8):\n",
    "    \"\"\"Visualize a batch from the dataloader.\"\"\"\n",
    "    config = MODEL_CONFIGS[model_name]\n",
    "    mean = np.array(config['mean'])\n",
    "    std = np.array(config['std'])\n",
    "    \n",
    "    images, labels = next(iter(dataloader))\n",
    "    n_samples = min(n_samples, len(images))\n",
    "    \n",
    "    n_cols = 4\n",
    "    n_rows = (n_samples + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(14, 4*n_rows))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        img = images[i].permute(1, 2, 0).numpy()\n",
    "        img = img * std + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        label_name = label_encoder.classes_[labels[i]]\n",
    "        \n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f\"{label_name[:20]}..\" if len(label_name) > 20 else label_name, fontsize=9)\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    for i in range(n_samples, len(axes)):\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'{model_name.upper()} - Training Batch', fontsize=12, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize batch for each model\n",
    "for model_name in MODEL_CONFIGS.keys():\n",
    "    visualize_batch(all_dataloaders[model_name]['train'], model_name, n_samples=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Save Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all configuration\n",
    "preprocessing_config = {\n",
    "    'config': CONFIG,\n",
    "    'model_configs': MODEL_CONFIGS,\n",
    "    'class_names': list(label_encoder.classes_),\n",
    "    'imagenet_mean': IMAGENET_MEAN,\n",
    "    'imagenet_std': IMAGENET_STD,\n",
    "    'dataset_stats': {\n",
    "        'total_samples': len(df),\n",
    "        'train_size': len(train_df),\n",
    "        'val_size': len(val_df),\n",
    "        'test_size': len(test_df),\n",
    "        'class_distribution': df['label'].value_counts().to_dict()\n",
    "    }\n",
    "}\n",
    "\n",
    "config_path = os.path.join(OUTPUT_DIR, 'preprocessing_config.json')\n",
    "with open(config_path, 'w') as f:\n",
    "    json.dump(preprocessing_config, f, indent=2)\n",
    "\n",
    "print(f\"Configuration saved to {config_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary\n",
    "print(\"=\"*70)\n",
    "print(\"                    PREPROCESSING COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìÅ Output Directory: {OUTPUT_DIR}\")\n",
    "\n",
    "print(f\"\\nüìä Dataset Splits:\")\n",
    "print(f\"   Train: {len(train_df)} samples\")\n",
    "print(f\"   Val:   {len(val_df)} samples\")\n",
    "print(f\"   Test:  {len(test_df)} samples\")\n",
    "\n",
    "print(f\"\\nüè∑Ô∏è Classes ({CONFIG['num_classes']}):\")\n",
    "for i, name in enumerate(label_encoder.classes_):\n",
    "    train_count = (train_df['label_encoded'] == i).sum()\n",
    "    print(f\"   {i}: {name} ({train_count} train samples)\")\n",
    "\n",
    "print(f\"\\nü§ñ Models Ready:\")\n",
    "for model_name, config in MODEL_CONFIGS.items():\n",
    "    print(f\"   - {model_name}: {config['input_size']}x{config['input_size']}\")\n",
    "\n",
    "print(f\"\\n‚öñÔ∏è Class Imbalance Handling:\")\n",
    "print(f\"   - Weighted sampling: ENABLED\")\n",
    "print(f\"   - Class weights saved for loss function\")\n",
    "\n",
    "print(f\"\\nüì¶ Files Saved:\")\n",
    "files = ['train.csv', 'val.csv', 'test.csv', 'label_encoder.pkl', \n",
    "         'class_weights.pt', 'preprocessing_config.json']\n",
    "for f in files:\n",
    "    path = os.path.join(OUTPUT_DIR, f)\n",
    "    exists = '‚úì' if os.path.exists(path) else '‚úó'\n",
    "    print(f\"   {exists} {f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Ready for model training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Code for Training Notebook\n",
    "\n",
    "Use this code to load the preprocessed data:\n",
    "\n",
    "```python\n",
    "import json\n",
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "OUTPUT_DIR = \"/content/drive/MyDrive/FS_Classification_Processed\"\n",
    "\n",
    "# Load configuration\n",
    "with open(f'{OUTPUT_DIR}/preprocessing_config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Load splits\n",
    "train_df = pd.read_csv(f'{OUTPUT_DIR}/train.csv')\n",
    "val_df = pd.read_csv(f'{OUTPUT_DIR}/val.csv')\n",
    "test_df = pd.read_csv(f'{OUTPUT_DIR}/test.csv')\n",
    "\n",
    "# Load label encoder\n",
    "with open(f'{OUTPUT_DIR}/label_encoder.pkl', 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "# Load class weights for loss function\n",
    "class_weights = torch.load(f'{OUTPUT_DIR}/class_weights.pt')\n",
    "\n",
    "print(f\"Loaded {len(train_df)} train, {len(val_df)} val, {len(test_df)} test samples\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
