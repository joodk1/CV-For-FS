{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Statements Page Classification - Exploratory Data Analysis (EDA)\n",
    "\n",
    "## Project Overview\n",
    "This notebook performs comprehensive EDA on Arabic financial statements to prepare for building a computer vision classification model.\n",
    "\n",
    "### Classification Classes:\n",
    "1. **Independent Auditor's Report** - Pages with auditor comments and opinions\n",
    "2. **Financial Sheets** - Balance Sheet, Income Statement, Cash Flow, Statement of Change in Equity\n",
    "3. **Notes about Financial Statements (Tabular)** - Notes containing at least one table\n",
    "4. **Notes about Financial Statements (Text)** - Notes without tables\n",
    "5. **Other Pages** - Cover pages, table of contents, etc.\n",
    "\n",
    "### Key Constraints:\n",
    "- Documents are in **Arabic** - text extraction is unreliable\n",
    "- Focus on **visual/structural features** for classification\n",
    "- Table detection is critical for distinguishing Tabular vs Text notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Environment Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q pdf2image pymupdf Pillow opencv-python-headless matplotlib seaborn pandas numpy scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install poppler for pdf2image (required on Colab)\n",
    "!apt-get install -q poppler-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "# Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# Utilities\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"All imports successful!\")\n",
    "print(f\"OpenCV version: {cv2.__version__}\")\n",
    "print(f\"PyMuPDF version: {fitz.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Loading & Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (for Colab)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CONFIGURE YOUR DATA PATH HERE\n",
    "# ============================================\n",
    "\n",
    "# Option 1: If data is in Google Drive\n",
    "DATA_PATH = \"/content/drive/MyDrive/YOUR_DATASET_FOLDER\"  # <-- UPDATE THIS PATH\n",
    "\n",
    "# Option 2: If you uploaded to Colab directly\n",
    "# DATA_PATH = \"/content/your_uploaded_folder\"\n",
    "\n",
    "# Option 3: If data is already extracted as images\n",
    "# IMAGES_PATH = \"/content/drive/MyDrive/extracted_images\"\n",
    "\n",
    "# Check if path exists\n",
    "if os.path.exists(DATA_PATH):\n",
    "    print(f\"Data path found: {DATA_PATH}\")\n",
    "    print(f\"Contents: {os.listdir(DATA_PATH)[:20]}...\")  # Show first 20 items\n",
    "else:\n",
    "    print(f\"WARNING: Path '{DATA_PATH}' not found!\")\n",
    "    print(\"Please update DATA_PATH to point to your dataset folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Dataset Structure Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_directory_structure(root_path: str, max_depth: int = 3) -> Dict:\n",
    "    \"\"\"\n",
    "    Recursively explore directory structure and gather statistics.\n",
    "    \n",
    "    Args:\n",
    "        root_path: Root directory to explore\n",
    "        max_depth: Maximum depth to traverse\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with structure information\n",
    "    \"\"\"\n",
    "    structure = {\n",
    "        'total_files': 0,\n",
    "        'total_folders': 0,\n",
    "        'file_types': Counter(),\n",
    "        'folder_contents': {},\n",
    "        'pdf_files': [],\n",
    "        'image_files': [],\n",
    "        'depth_distribution': Counter()\n",
    "    }\n",
    "    \n",
    "    image_extensions = {'.jpg', '.jpeg', '.png', '.tiff', '.tif', '.bmp', '.gif'}\n",
    "    \n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        depth = root.replace(root_path, '').count(os.sep)\n",
    "        if depth > max_depth:\n",
    "            continue\n",
    "            \n",
    "        structure['total_folders'] += len(dirs)\n",
    "        structure['depth_distribution'][depth] += len(files)\n",
    "        \n",
    "        rel_path = os.path.relpath(root, root_path)\n",
    "        structure['folder_contents'][rel_path] = len(files)\n",
    "        \n",
    "        for file in files:\n",
    "            structure['total_files'] += 1\n",
    "            ext = os.path.splitext(file)[1].lower()\n",
    "            structure['file_types'][ext] += 1\n",
    "            \n",
    "            full_path = os.path.join(root, file)\n",
    "            if ext == '.pdf':\n",
    "                structure['pdf_files'].append(full_path)\n",
    "            elif ext in image_extensions:\n",
    "                structure['image_files'].append(full_path)\n",
    "    \n",
    "    return structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore dataset structure\n",
    "print(\"=\"*60)\n",
    "print(\"DATASET STRUCTURE EXPLORATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "dataset_info = explore_directory_structure(DATA_PATH)\n",
    "\n",
    "print(f\"\\nðŸ“ Total Folders: {dataset_info['total_folders']}\")\n",
    "print(f\"ðŸ“„ Total Files: {dataset_info['total_files']}\")\n",
    "print(f\"ðŸ“‘ PDF Files: {len(dataset_info['pdf_files'])}\")\n",
    "print(f\"ðŸ–¼ï¸  Image Files: {len(dataset_info['image_files'])}\")\n",
    "\n",
    "print(\"\\nðŸ“Š File Type Distribution:\")\n",
    "for ext, count in sorted(dataset_info['file_types'].items(), key=lambda x: -x[1]):\n",
    "    print(f\"   {ext if ext else '(no extension)'}: {count} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize file type distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# File types pie chart\n",
    "file_types = dict(dataset_info['file_types'])\n",
    "if file_types:\n",
    "    labels = [k if k else 'no ext' for k in file_types.keys()]\n",
    "    sizes = list(file_types.values())\n",
    "    explode = [0.05 if l == '.pdf' else 0 for l in labels]\n",
    "    \n",
    "    axes[0].pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%',\n",
    "                shadow=True, startangle=90)\n",
    "    axes[0].set_title('File Type Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Folder content distribution\n",
    "folder_contents = dataset_info['folder_contents']\n",
    "if folder_contents:\n",
    "    # Show top 15 folders by file count\n",
    "    sorted_folders = sorted(folder_contents.items(), key=lambda x: -x[1])[:15]\n",
    "    folders, counts = zip(*sorted_folders)\n",
    "    folders = [f[:30] + '...' if len(f) > 30 else f for f in folders]  # Truncate long names\n",
    "    \n",
    "    axes[1].barh(range(len(folders)), counts, color=sns.color_palette('viridis', len(folders)))\n",
    "    axes[1].set_yticks(range(len(folders)))\n",
    "    axes[1].set_yticklabels(folders)\n",
    "    axes[1].set_xlabel('Number of Files')\n",
    "    axes[1].set_title('Top 15 Folders by File Count', fontsize=14, fontweight='bold')\n",
    "    axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. PDF Document Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_pdf(pdf_path: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Extract metadata and statistics from a PDF file.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to PDF file\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with PDF metadata and statistics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        \n",
    "        # Get page dimensions\n",
    "        page_sizes = []\n",
    "        for page in doc:\n",
    "            rect = page.rect\n",
    "            page_sizes.append({\n",
    "                'width': rect.width,\n",
    "                'height': rect.height,\n",
    "                'aspect_ratio': rect.width / rect.height if rect.height > 0 else 0\n",
    "            })\n",
    "        \n",
    "        info = {\n",
    "            'filename': os.path.basename(pdf_path),\n",
    "            'filepath': pdf_path,\n",
    "            'num_pages': len(doc),\n",
    "            'file_size_mb': os.path.getsize(pdf_path) / (1024 * 1024),\n",
    "            'metadata': doc.metadata,\n",
    "            'page_sizes': page_sizes,\n",
    "            'avg_width': np.mean([p['width'] for p in page_sizes]) if page_sizes else 0,\n",
    "            'avg_height': np.mean([p['height'] for p in page_sizes]) if page_sizes else 0,\n",
    "            'is_encrypted': doc.is_encrypted,\n",
    "            'has_toc': len(doc.get_toc()) > 0\n",
    "        }\n",
    "        \n",
    "        doc.close()\n",
    "        return info\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'filename': os.path.basename(pdf_path),\n",
    "            'filepath': pdf_path,\n",
    "            'error': str(e)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze all PDF files\n",
    "print(\"Analyzing PDF documents...\")\n",
    "pdf_analyses = []\n",
    "\n",
    "for pdf_path in tqdm(dataset_info['pdf_files'], desc=\"Processing PDFs\"):\n",
    "    pdf_analyses.append(analyze_pdf(pdf_path))\n",
    "\n",
    "# Create DataFrame for analysis\n",
    "pdf_df = pd.DataFrame([p for p in pdf_analyses if 'error' not in p])\n",
    "error_pdfs = [p for p in pdf_analyses if 'error' in p]\n",
    "\n",
    "print(f\"\\nâœ… Successfully analyzed: {len(pdf_df)} PDFs\")\n",
    "print(f\"âŒ Failed to analyze: {len(error_pdfs)} PDFs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF Statistics Summary\n",
    "if len(pdf_df) > 0:\n",
    "    print(\"=\"*60)\n",
    "    print(\"PDF DOCUMENTS STATISTICS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nðŸ“„ Total PDFs: {len(pdf_df)}\")\n",
    "    print(f\"ðŸ“ƒ Total Pages: {pdf_df['num_pages'].sum():,}\")\n",
    "    print(f\"ðŸ’¾ Total Size: {pdf_df['file_size_mb'].sum():.2f} MB\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Pages per Document:\")\n",
    "    print(f\"   Min: {pdf_df['num_pages'].min()}\")\n",
    "    print(f\"   Max: {pdf_df['num_pages'].max()}\")\n",
    "    print(f\"   Mean: {pdf_df['num_pages'].mean():.1f}\")\n",
    "    print(f\"   Median: {pdf_df['num_pages'].median():.1f}\")\n",
    "    print(f\"   Std Dev: {pdf_df['num_pages'].std():.1f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“ Page Dimensions (average):\")\n",
    "    print(f\"   Width: {pdf_df['avg_width'].mean():.1f} pts\")\n",
    "    print(f\"   Height: {pdf_df['avg_height'].mean():.1f} pts\")\n",
    "    \n",
    "    print(f\"\\nðŸ” Encrypted PDFs: {pdf_df['is_encrypted'].sum()}\")\n",
    "    print(f\"ðŸ“‘ PDFs with Table of Contents: {pdf_df['has_toc'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize PDF statistics\n",
    "if len(pdf_df) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Pages per document distribution\n",
    "    axes[0, 0].hist(pdf_df['num_pages'], bins=30, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    axes[0, 0].axvline(pdf_df['num_pages'].mean(), color='red', linestyle='--', label=f'Mean: {pdf_df[\"num_pages\"].mean():.1f}')\n",
    "    axes[0, 0].axvline(pdf_df['num_pages'].median(), color='green', linestyle='--', label=f'Median: {pdf_df[\"num_pages\"].median():.1f}')\n",
    "    axes[0, 0].set_xlabel('Number of Pages')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].set_title('Distribution of Pages per Document', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # File size distribution\n",
    "    axes[0, 1].hist(pdf_df['file_size_mb'], bins=30, color='coral', edgecolor='black', alpha=0.7)\n",
    "    axes[0, 1].axvline(pdf_df['file_size_mb'].mean(), color='red', linestyle='--', label=f'Mean: {pdf_df[\"file_size_mb\"].mean():.2f} MB')\n",
    "    axes[0, 1].set_xlabel('File Size (MB)')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].set_title('Distribution of File Sizes', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # Pages vs File Size scatter\n",
    "    axes[1, 0].scatter(pdf_df['num_pages'], pdf_df['file_size_mb'], alpha=0.6, c='purple')\n",
    "    axes[1, 0].set_xlabel('Number of Pages')\n",
    "    axes[1, 0].set_ylabel('File Size (MB)')\n",
    "    axes[1, 0].set_title('Pages vs File Size Correlation', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Page dimensions\n",
    "    axes[1, 1].scatter(pdf_df['avg_width'], pdf_df['avg_height'], alpha=0.6, c='teal')\n",
    "    axes[1, 1].set_xlabel('Average Page Width (pts)')\n",
    "    axes[1, 1].set_ylabel('Average Page Height (pts)')\n",
    "    axes[1, 1].set_title('Page Dimension Distribution', fontsize=12, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Correlation\n",
    "    correlation = pdf_df['num_pages'].corr(pdf_df['file_size_mb'])\n",
    "    print(f\"\\nðŸ“ˆ Correlation between pages and file size: {correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show PDF DataFrame\n",
    "if len(pdf_df) > 0:\n",
    "    display_cols = ['filename', 'num_pages', 'file_size_mb', 'avg_width', 'avg_height', 'is_encrypted', 'has_toc']\n",
    "    print(\"\\nðŸ“‹ PDF Documents Overview (first 20):\")\n",
    "    display(pdf_df[display_cols].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Page Extraction & Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pages_as_images(pdf_path: str, dpi: int = 150, max_pages: int = None) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extract pages from PDF as images using PyMuPDF.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to PDF file\n",
    "        dpi: Resolution for rendering\n",
    "        max_pages: Maximum number of pages to extract (None for all)\n",
    "    \n",
    "    Returns:\n",
    "        List of images as numpy arrays (RGB)\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        zoom = dpi / 72  # 72 is the default PDF resolution\n",
    "        mat = fitz.Matrix(zoom, zoom)\n",
    "        \n",
    "        pages_to_extract = min(len(doc), max_pages) if max_pages else len(doc)\n",
    "        \n",
    "        for page_num in range(pages_to_extract):\n",
    "            page = doc[page_num]\n",
    "            pix = page.get_pixmap(matrix=mat)\n",
    "            \n",
    "            # Convert to numpy array\n",
    "            img = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.height, pix.width, pix.n)\n",
    "            \n",
    "            # Convert to RGB if needed\n",
    "            if pix.n == 4:  # RGBA\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)\n",
    "            elif pix.n == 1:  # Grayscale\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "                \n",
    "            images.append(img)\n",
    "        \n",
    "        doc.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting {pdf_path}: {e}\")\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_image_properties(img: np.ndarray) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze visual properties of an image.\n",
    "    \n",
    "    Args:\n",
    "        img: Image as numpy array (RGB)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with image properties\n",
    "    \"\"\"\n",
    "    height, width = img.shape[:2]\n",
    "    \n",
    "    # Convert to grayscale for analysis\n",
    "    if len(img.shape) == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = img\n",
    "    \n",
    "    # Edge detection for structural analysis\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    edge_density = np.sum(edges > 0) / (height * width)\n",
    "    \n",
    "    # Line detection using Hough Transform\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=100, minLineLength=50, maxLineGap=10)\n",
    "    num_lines = len(lines) if lines is not None else 0\n",
    "    \n",
    "    # Separate horizontal and vertical lines\n",
    "    horizontal_lines = 0\n",
    "    vertical_lines = 0\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            angle = np.abs(np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi)\n",
    "            if angle < 15 or angle > 165:  # Horizontal\n",
    "                horizontal_lines += 1\n",
    "            elif 75 < angle < 105:  # Vertical\n",
    "                vertical_lines += 1\n",
    "    \n",
    "    # Contour analysis\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_contours = len(contours)\n",
    "    \n",
    "    # Calculate white space ratio\n",
    "    _, binary = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY)\n",
    "    white_space_ratio = np.sum(binary == 255) / (height * width)\n",
    "    \n",
    "    # Text density estimation (inverse of white space in document area)\n",
    "    text_density = 1 - white_space_ratio\n",
    "    \n",
    "    return {\n",
    "        'width': width,\n",
    "        'height': height,\n",
    "        'aspect_ratio': width / height,\n",
    "        'edge_density': edge_density,\n",
    "        'num_lines': num_lines,\n",
    "        'horizontal_lines': horizontal_lines,\n",
    "        'vertical_lines': vertical_lines,\n",
    "        'num_contours': num_contours,\n",
    "        'white_space_ratio': white_space_ratio,\n",
    "        'text_density': text_density\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and analyze sample pages from each PDF\n",
    "print(\"Extracting and analyzing sample pages from PDFs...\")\n",
    "print(\"(This may take a while depending on dataset size)\\n\")\n",
    "\n",
    "all_page_analyses = []\n",
    "sample_images = {}  # Store some sample images for visualization\n",
    "\n",
    "# Analyze pages from each PDF\n",
    "for pdf_info in tqdm(pdf_analyses[:], desc=\"Analyzing PDFs\"):\n",
    "    if 'error' in pdf_info:\n",
    "        continue\n",
    "    \n",
    "    pdf_path = pdf_info['filepath']\n",
    "    pdf_name = pdf_info['filename']\n",
    "    \n",
    "    # Extract all pages\n",
    "    images = extract_pages_as_images(pdf_path, dpi=150)\n",
    "    \n",
    "    for page_idx, img in enumerate(images):\n",
    "        props = analyze_image_properties(img)\n",
    "        props['pdf_name'] = pdf_name\n",
    "        props['page_num'] = page_idx + 1\n",
    "        props['pdf_path'] = pdf_path\n",
    "        all_page_analyses.append(props)\n",
    "        \n",
    "        # Store sample images (first, middle, last page of first 5 PDFs)\n",
    "        if len(sample_images) < 50:\n",
    "            key = f\"{pdf_name}_page{page_idx+1}\"\n",
    "            if page_idx == 0 or page_idx == len(images)//2 or page_idx == len(images)-1:\n",
    "                sample_images[key] = img\n",
    "\n",
    "page_df = pd.DataFrame(all_page_analyses)\n",
    "print(f\"\\nâœ… Analyzed {len(page_df)} pages from {len(pdf_df)} PDFs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Page-level statistics\n",
    "if len(page_df) > 0:\n",
    "    print(\"=\"*60)\n",
    "    print(\"PAGE-LEVEL IMAGE STATISTICS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nðŸ“„ Total Pages Analyzed: {len(page_df)}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“ Image Dimensions:\")\n",
    "    print(f\"   Width  - Min: {page_df['width'].min()}, Max: {page_df['width'].max()}, Mean: {page_df['width'].mean():.1f}\")\n",
    "    print(f\"   Height - Min: {page_df['height'].min()}, Max: {page_df['height'].max()}, Mean: {page_df['height'].mean():.1f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“ Aspect Ratios:\")\n",
    "    print(f\"   Min: {page_df['aspect_ratio'].min():.3f}\")\n",
    "    print(f\"   Max: {page_df['aspect_ratio'].max():.3f}\")\n",
    "    print(f\"   Mean: {page_df['aspect_ratio'].mean():.3f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Structural Features:\")\n",
    "    print(f\"   Edge Density    - Mean: {page_df['edge_density'].mean():.4f}, Std: {page_df['edge_density'].std():.4f}\")\n",
    "    print(f\"   Lines Detected  - Mean: {page_df['num_lines'].mean():.1f}, Std: {page_df['num_lines'].std():.1f}\")\n",
    "    print(f\"   Horizontal Lines- Mean: {page_df['horizontal_lines'].mean():.1f}\")\n",
    "    print(f\"   Vertical Lines  - Mean: {page_df['vertical_lines'].mean():.1f}\")\n",
    "    print(f\"   Contours        - Mean: {page_df['num_contours'].mean():.1f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“ Content Metrics:\")\n",
    "    print(f\"   White Space Ratio - Mean: {page_df['white_space_ratio'].mean():.3f}\")\n",
    "    print(f\"   Text Density      - Mean: {page_df['text_density'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize page-level statistics\n",
    "if len(page_df) > 0:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "    \n",
    "    # Edge density distribution\n",
    "    axes[0, 0].hist(page_df['edge_density'], bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    axes[0, 0].set_xlabel('Edge Density')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].set_title('Edge Density Distribution', fontweight='bold')\n",
    "    \n",
    "    # Number of lines distribution\n",
    "    axes[0, 1].hist(page_df['num_lines'], bins=50, color='coral', edgecolor='black', alpha=0.7)\n",
    "    axes[0, 1].set_xlabel('Number of Lines')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].set_title('Lines Detected Distribution', fontweight='bold')\n",
    "    \n",
    "    # Horizontal vs Vertical lines\n",
    "    axes[0, 2].scatter(page_df['horizontal_lines'], page_df['vertical_lines'], alpha=0.3, c='purple')\n",
    "    axes[0, 2].set_xlabel('Horizontal Lines')\n",
    "    axes[0, 2].set_ylabel('Vertical Lines')\n",
    "    axes[0, 2].set_title('Horizontal vs Vertical Lines', fontweight='bold')\n",
    "    \n",
    "    # White space ratio\n",
    "    axes[1, 0].hist(page_df['white_space_ratio'], bins=50, color='teal', edgecolor='black', alpha=0.7)\n",
    "    axes[1, 0].set_xlabel('White Space Ratio')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].set_title('White Space Ratio Distribution', fontweight='bold')\n",
    "    \n",
    "    # Contours distribution\n",
    "    axes[1, 1].hist(page_df['num_contours'], bins=50, color='orange', edgecolor='black', alpha=0.7)\n",
    "    axes[1, 1].set_xlabel('Number of Contours')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    axes[1, 1].set_title('Contours Distribution', fontweight='bold')\n",
    "    \n",
    "    # Aspect ratio\n",
    "    axes[1, 2].hist(page_df['aspect_ratio'], bins=30, color='green', edgecolor='black', alpha=0.7)\n",
    "    axes[1, 2].set_xlabel('Aspect Ratio (W/H)')\n",
    "    axes[1, 2].set_ylabel('Frequency')\n",
    "    axes[1, 2].set_title('Aspect Ratio Distribution', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Table Detection Analysis\n",
    "\n",
    "Critical for distinguishing **Notes (Tabular)** vs **Notes (Text)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_tables_morphological(img: np.ndarray, min_table_area_ratio: float = 0.01) -> Dict:\n",
    "    \"\"\"\n",
    "    Detect tables using morphological operations.\n",
    "    A table is defined as structured element with at least 1 row and 2 columns \n",
    "    or at least 2 rows and 1 column, separated by visible lines.\n",
    "    \n",
    "    Args:\n",
    "        img: Input image (RGB)\n",
    "        min_table_area_ratio: Minimum area ratio for a valid table\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with table detection results\n",
    "    \"\"\"\n",
    "    height, width = img.shape[:2]\n",
    "    total_area = height * width\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    if len(img.shape) == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = img.copy()\n",
    "    \n",
    "    # Threshold to binary (invert so lines are white)\n",
    "    _, binary = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # Detect horizontal lines\n",
    "    horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (width // 30, 1))\n",
    "    horizontal_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, horizontal_kernel, iterations=2)\n",
    "    \n",
    "    # Detect vertical lines\n",
    "    vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, height // 30))\n",
    "    vertical_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, vertical_kernel, iterations=2)\n",
    "    \n",
    "    # Combine horizontal and vertical lines\n",
    "    table_mask = cv2.add(horizontal_lines, vertical_lines)\n",
    "    \n",
    "    # Dilate to connect nearby lines\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    table_mask = cv2.dilate(table_mask, kernel, iterations=2)\n",
    "    \n",
    "    # Find contours of potential tables\n",
    "    contours, _ = cv2.findContours(table_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    tables_found = []\n",
    "    total_table_area = 0\n",
    "    \n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        area = w * h\n",
    "        area_ratio = area / total_area\n",
    "        \n",
    "        # Filter by minimum area and aspect ratio\n",
    "        if area_ratio >= min_table_area_ratio and w > 50 and h > 30:\n",
    "            # Count lines within this region\n",
    "            region_h = horizontal_lines[y:y+h, x:x+w]\n",
    "            region_v = vertical_lines[y:y+h, x:x+w]\n",
    "            \n",
    "            # Find horizontal line segments\n",
    "            h_lines = cv2.HoughLinesP(region_h, 1, np.pi/180, threshold=30, minLineLength=w//4, maxLineGap=10)\n",
    "            v_lines = cv2.HoughLinesP(region_v, 1, np.pi/180, threshold=30, minLineLength=h//4, maxLineGap=10)\n",
    "            \n",
    "            num_h_lines = len(h_lines) if h_lines is not None else 0\n",
    "            num_v_lines = len(v_lines) if v_lines is not None else 0\n",
    "            \n",
    "            # Check if it qualifies as a table (at least 1 row and 2 columns OR 2 rows and 1 column)\n",
    "            # Rows are separated by horizontal lines, columns by vertical lines\n",
    "            is_table = (num_h_lines >= 1 and num_v_lines >= 2) or (num_h_lines >= 2 and num_v_lines >= 1)\n",
    "            \n",
    "            if is_table:\n",
    "                tables_found.append({\n",
    "                    'bbox': (x, y, w, h),\n",
    "                    'area': area,\n",
    "                    'area_ratio': area_ratio,\n",
    "                    'h_lines': num_h_lines,\n",
    "                    'v_lines': num_v_lines\n",
    "                })\n",
    "                total_table_area += area\n",
    "    \n",
    "    # Calculate line densities\n",
    "    h_line_pixels = np.sum(horizontal_lines > 0)\n",
    "    v_line_pixels = np.sum(vertical_lines > 0)\n",
    "    \n",
    "    return {\n",
    "        'has_table': len(tables_found) > 0,\n",
    "        'num_tables': len(tables_found),\n",
    "        'tables': tables_found,\n",
    "        'total_table_area_ratio': total_table_area / total_area,\n",
    "        'h_line_density': h_line_pixels / total_area,\n",
    "        'v_line_density': v_line_pixels / total_area,\n",
    "        'table_mask': table_mask\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_tables_grid_based(img: np.ndarray) -> Dict:\n",
    "    \"\"\"\n",
    "    Alternative table detection using grid intersection analysis.\n",
    "    \n",
    "    Args:\n",
    "        img: Input image (RGB)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with grid-based table detection results\n",
    "    \"\"\"\n",
    "    height, width = img.shape[:2]\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    if len(img.shape) == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = img.copy()\n",
    "    \n",
    "    # Apply adaptive threshold\n",
    "    binary = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                    cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    \n",
    "    # Detect horizontal lines\n",
    "    h_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (width // 20, 1))\n",
    "    h_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, h_kernel)\n",
    "    \n",
    "    # Detect vertical lines  \n",
    "    v_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, height // 20))\n",
    "    v_lines = cv2.morphologyEx(binary, cv2.MORPH_OPEN, v_kernel)\n",
    "    \n",
    "    # Find intersections\n",
    "    intersections = cv2.bitwise_and(h_lines, v_lines)\n",
    "    \n",
    "    # Dilate intersections\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "    intersections = cv2.dilate(intersections, kernel, iterations=2)\n",
    "    \n",
    "    # Count intersection points\n",
    "    contours, _ = cv2.findContours(intersections, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    num_intersections = len(contours)\n",
    "    \n",
    "    # Combined table structure\n",
    "    table_structure = cv2.add(h_lines, v_lines)\n",
    "    structure_ratio = np.sum(table_structure > 0) / (height * width)\n",
    "    \n",
    "    # A table typically has multiple intersections forming a grid\n",
    "    # Minimum 4 intersections for a simple 2x2 grid\n",
    "    likely_has_table = num_intersections >= 4 and structure_ratio > 0.005\n",
    "    \n",
    "    return {\n",
    "        'likely_has_table': likely_has_table,\n",
    "        'num_intersections': num_intersections,\n",
    "        'structure_ratio': structure_ratio,\n",
    "        'intersection_density': num_intersections / (height * width) * 10000  # Per 10k pixels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform table detection on all pages\n",
    "print(\"Performing table detection analysis on all pages...\")\n",
    "\n",
    "table_analyses = []\n",
    "\n",
    "for pdf_info in tqdm(pdf_analyses[:], desc=\"Table Detection\"):\n",
    "    if 'error' in pdf_info:\n",
    "        continue\n",
    "    \n",
    "    pdf_path = pdf_info['filepath']\n",
    "    pdf_name = pdf_info['filename']\n",
    "    \n",
    "    images = extract_pages_as_images(pdf_path, dpi=150)\n",
    "    \n",
    "    for page_idx, img in enumerate(images):\n",
    "        # Morphological table detection\n",
    "        morph_result = detect_tables_morphological(img)\n",
    "        \n",
    "        # Grid-based table detection\n",
    "        grid_result = detect_tables_grid_based(img)\n",
    "        \n",
    "        table_analyses.append({\n",
    "            'pdf_name': pdf_name,\n",
    "            'page_num': page_idx + 1,\n",
    "            'has_table_morph': morph_result['has_table'],\n",
    "            'num_tables_morph': morph_result['num_tables'],\n",
    "            'table_area_ratio': morph_result['total_table_area_ratio'],\n",
    "            'h_line_density': morph_result['h_line_density'],\n",
    "            'v_line_density': morph_result['v_line_density'],\n",
    "            'has_table_grid': grid_result['likely_has_table'],\n",
    "            'num_intersections': grid_result['num_intersections'],\n",
    "            'structure_ratio': grid_result['structure_ratio'],\n",
    "            'intersection_density': grid_result['intersection_density']\n",
    "        })\n",
    "\n",
    "table_df = pd.DataFrame(table_analyses)\n",
    "print(f\"\\nâœ… Table detection completed for {len(table_df)} pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table detection statistics\n",
    "if len(table_df) > 0:\n",
    "    print(\"=\"*60)\n",
    "    print(\"TABLE DETECTION ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Combine both methods for final determination\n",
    "    table_df['has_table_combined'] = table_df['has_table_morph'] | table_df['has_table_grid']\n",
    "    \n",
    "    pages_with_tables = table_df['has_table_combined'].sum()\n",
    "    pages_without_tables = len(table_df) - pages_with_tables\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Table Detection Results:\")\n",
    "    print(f\"   Pages WITH tables: {pages_with_tables} ({pages_with_tables/len(table_df)*100:.1f}%)\")\n",
    "    print(f\"   Pages WITHOUT tables: {pages_without_tables} ({pages_without_tables/len(table_df)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Detection Method Comparison:\")\n",
    "    print(f\"   Morphological method detected tables in: {table_df['has_table_morph'].sum()} pages\")\n",
    "    print(f\"   Grid-based method detected tables in: {table_df['has_table_grid'].sum()} pages\")\n",
    "    \n",
    "    print(f\"\\nðŸ“ Table Area Statistics (for pages with tables):\")\n",
    "    table_pages = table_df[table_df['has_table_combined']]\n",
    "    if len(table_pages) > 0:\n",
    "        print(f\"   Mean table area ratio: {table_pages['table_area_ratio'].mean():.4f}\")\n",
    "        print(f\"   Max table area ratio: {table_pages['table_area_ratio'].max():.4f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ”² Line Density Statistics:\")\n",
    "    print(f\"   Horizontal line density - Mean: {table_df['h_line_density'].mean():.6f}\")\n",
    "    print(f\"   Vertical line density - Mean: {table_df['v_line_density'].mean():.6f}\")\n",
    "    print(f\"   Grid intersections - Mean: {table_df['num_intersections'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize table detection statistics\n",
    "if len(table_df) > 0:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "    \n",
    "    # Table presence pie chart\n",
    "    table_counts = table_df['has_table_combined'].value_counts()\n",
    "    labels = ['No Tables', 'Has Tables']\n",
    "    sizes = [table_counts.get(False, 0), table_counts.get(True, 0)]\n",
    "    colors = ['#ff9999', '#66b3ff']\n",
    "    axes[0, 0].pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "    axes[0, 0].set_title('Pages With/Without Tables', fontweight='bold')\n",
    "    \n",
    "    # Table area ratio distribution\n",
    "    axes[0, 1].hist(table_df['table_area_ratio'], bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    axes[0, 1].set_xlabel('Table Area Ratio')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].set_title('Table Area Ratio Distribution', fontweight='bold')\n",
    "    \n",
    "    # Number of intersections distribution\n",
    "    axes[0, 2].hist(table_df['num_intersections'], bins=50, color='coral', edgecolor='black', alpha=0.7)\n",
    "    axes[0, 2].set_xlabel('Number of Grid Intersections')\n",
    "    axes[0, 2].set_ylabel('Frequency')\n",
    "    axes[0, 2].set_title('Grid Intersection Distribution', fontweight='bold')\n",
    "    \n",
    "    # H vs V line density scatter\n",
    "    colors = ['red' if t else 'blue' for t in table_df['has_table_combined']]\n",
    "    axes[1, 0].scatter(table_df['h_line_density'], table_df['v_line_density'], c=colors, alpha=0.3)\n",
    "    axes[1, 0].set_xlabel('Horizontal Line Density')\n",
    "    axes[1, 0].set_ylabel('Vertical Line Density')\n",
    "    axes[1, 0].set_title('H vs V Line Density (Red=Table, Blue=No Table)', fontweight='bold')\n",
    "    \n",
    "    # Structure ratio distribution\n",
    "    axes[1, 1].hist(table_df['structure_ratio'], bins=50, color='green', edgecolor='black', alpha=0.7)\n",
    "    axes[1, 1].set_xlabel('Structure Ratio')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    axes[1, 1].set_title('Table Structure Ratio Distribution', fontweight='bold')\n",
    "    \n",
    "    # Method agreement\n",
    "    agreement = [\n",
    "        ((table_df['has_table_morph'] == True) & (table_df['has_table_grid'] == True)).sum(),\n",
    "        ((table_df['has_table_morph'] == True) & (table_df['has_table_grid'] == False)).sum(),\n",
    "        ((table_df['has_table_morph'] == False) & (table_df['has_table_grid'] == True)).sum(),\n",
    "        ((table_df['has_table_morph'] == False) & (table_df['has_table_grid'] == False)).sum()\n",
    "    ]\n",
    "    labels = ['Both: Table', 'Morph Only', 'Grid Only', 'Both: No Table']\n",
    "    axes[1, 2].bar(labels, agreement, color=['green', 'orange', 'purple', 'gray'])\n",
    "    axes[1, 2].set_ylabel('Number of Pages')\n",
    "    axes[1, 2].set_title('Detection Method Agreement', fontweight='bold')\n",
    "    axes[1, 2].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Visual Sample Gallery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample_pages(sample_images: Dict, n_samples: int = 12, figsize: Tuple = (20, 16)):\n",
    "    \"\"\"\n",
    "    Display a gallery of sample page images.\n",
    "    \n",
    "    Args:\n",
    "        sample_images: Dictionary of sample images\n",
    "        n_samples: Number of samples to display\n",
    "        figsize: Figure size\n",
    "    \"\"\"\n",
    "    samples = list(sample_images.items())[:n_samples]\n",
    "    n_cols = 4\n",
    "    n_rows = (len(samples) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=figsize)\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes] if n_cols == 1 else axes\n",
    "    \n",
    "    for idx, (name, img) in enumerate(samples):\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].set_title(name[:30] + '...' if len(name) > 30 else name, fontsize=9)\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for idx in range(len(samples), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle('Sample Page Gallery', fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample pages\n",
    "if sample_images:\n",
    "    print(f\"Displaying {min(12, len(sample_images))} sample pages...\")\n",
    "    display_sample_pages(sample_images, n_samples=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_table_detection(img: np.ndarray, pdf_name: str, page_num: int):\n",
    "    \"\"\"\n",
    "    Visualize table detection results on a single image.\n",
    "    \n",
    "    Args:\n",
    "        img: Input image\n",
    "        pdf_name: Name of the PDF\n",
    "        page_num: Page number\n",
    "    \"\"\"\n",
    "    result = detect_tables_morphological(img)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # Original image\n",
    "    axes[0].imshow(img)\n",
    "    axes[0].set_title(f'{pdf_name} - Page {page_num}\\n(Original)', fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Table mask\n",
    "    axes[1].imshow(result['table_mask'], cmap='gray')\n",
    "    axes[1].set_title(f'Detected Lines\\n(H: {result[\"h_line_density\"]:.5f}, V: {result[\"v_line_density\"]:.5f})', fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Image with table bounding boxes\n",
    "    img_with_boxes = img.copy()\n",
    "    for table in result['tables']:\n",
    "        x, y, w, h = table['bbox']\n",
    "        cv2.rectangle(img_with_boxes, (x, y), (x+w, y+h), (255, 0, 0), 3)\n",
    "    \n",
    "    axes[2].imshow(img_with_boxes)\n",
    "    has_table_text = 'TABLE DETECTED' if result['has_table'] else 'NO TABLE'\n",
    "    axes[2].set_title(f'{has_table_text}\\n({result[\"num_tables\"]} tables found)', fontweight='bold',\n",
    "                      color='green' if result['has_table'] else 'red')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize table detection on sample pages\n",
    "print(\"Visualizing table detection on sample pages...\\n\")\n",
    "\n",
    "# Get a few sample images for visualization\n",
    "sample_keys = list(sample_images.keys())[:6]\n",
    "\n",
    "for key in sample_keys:\n",
    "    parts = key.rsplit('_page', 1)\n",
    "    pdf_name = parts[0]\n",
    "    page_num = int(parts[1]) if len(parts) > 1 else 1\n",
    "    img = sample_images[key]\n",
    "    visualize_table_detection(img, pdf_name, page_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Layout & Structure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_page_layout(img: np.ndarray) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze page layout characteristics.\n",
    "    \n",
    "    Args:\n",
    "        img: Input image (RGB)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with layout analysis results\n",
    "    \"\"\"\n",
    "    height, width = img.shape[:2]\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    if len(img.shape) == 3:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = img.copy()\n",
    "    \n",
    "    # Binary threshold\n",
    "    _, binary = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "    \n",
    "    # Analyze content distribution in different regions\n",
    "    # Divide page into 3x3 grid\n",
    "    h_third = height // 3\n",
    "    w_third = width // 3\n",
    "    \n",
    "    region_densities = {}\n",
    "    regions = [\n",
    "        ('top_left', (0, 0, w_third, h_third)),\n",
    "        ('top_center', (w_third, 0, 2*w_third, h_third)),\n",
    "        ('top_right', (2*w_third, 0, width, h_third)),\n",
    "        ('middle_left', (0, h_third, w_third, 2*h_third)),\n",
    "        ('middle_center', (w_third, h_third, 2*w_third, 2*h_third)),\n",
    "        ('middle_right', (2*w_third, h_third, width, 2*h_third)),\n",
    "        ('bottom_left', (0, 2*h_third, w_third, height)),\n",
    "        ('bottom_center', (w_third, 2*h_third, 2*w_third, height)),\n",
    "        ('bottom_right', (2*w_third, 2*h_third, width, height))\n",
    "    ]\n",
    "    \n",
    "    for name, (x1, y1, x2, y2) in regions:\n",
    "        region = binary[y1:y2, x1:x2]\n",
    "        region_densities[name] = np.sum(region > 0) / region.size\n",
    "    \n",
    "    # Analyze margins (top 5%, bottom 5%, left 5%, right 5%)\n",
    "    margin_size = int(min(height, width) * 0.05)\n",
    "    margins = {\n",
    "        'top_margin_density': np.sum(binary[:margin_size, :] > 0) / (margin_size * width),\n",
    "        'bottom_margin_density': np.sum(binary[-margin_size:, :] > 0) / (margin_size * width),\n",
    "        'left_margin_density': np.sum(binary[:, :margin_size] > 0) / (height * margin_size),\n",
    "        'right_margin_density': np.sum(binary[:, -margin_size:] > 0) / (height * margin_size)\n",
    "    }\n",
    "    \n",
    "    # Calculate header and footer presence (top/bottom 10%)\n",
    "    header_region = binary[:int(height*0.1), :]\n",
    "    footer_region = binary[-int(height*0.1):, :]\n",
    "    \n",
    "    header_density = np.sum(header_region > 0) / header_region.size\n",
    "    footer_density = np.sum(footer_region > 0) / footer_region.size\n",
    "    \n",
    "    # Content distribution (variance across horizontal bands)\n",
    "    band_densities = []\n",
    "    num_bands = 10\n",
    "    band_height = height // num_bands\n",
    "    for i in range(num_bands):\n",
    "        band = binary[i*band_height:(i+1)*band_height, :]\n",
    "        band_densities.append(np.sum(band > 0) / band.size)\n",
    "    \n",
    "    content_distribution_variance = np.var(band_densities)\n",
    "    \n",
    "    return {\n",
    "        **region_densities,\n",
    "        **margins,\n",
    "        'header_density': header_density,\n",
    "        'footer_density': footer_density,\n",
    "        'content_distribution_variance': content_distribution_variance,\n",
    "        'band_densities': band_densities\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze layout for all pages\n",
    "print(\"Analyzing page layouts...\")\n",
    "\n",
    "layout_analyses = []\n",
    "\n",
    "for pdf_info in tqdm(pdf_analyses[:], desc=\"Layout Analysis\"):\n",
    "    if 'error' in pdf_info:\n",
    "        continue\n",
    "    \n",
    "    pdf_path = pdf_info['filepath']\n",
    "    pdf_name = pdf_info['filename']\n",
    "    \n",
    "    images = extract_pages_as_images(pdf_path, dpi=150)\n",
    "    \n",
    "    for page_idx, img in enumerate(images):\n",
    "        layout = analyze_page_layout(img)\n",
    "        layout['pdf_name'] = pdf_name\n",
    "        layout['page_num'] = page_idx + 1\n",
    "        layout_analyses.append(layout)\n",
    "\n",
    "layout_df = pd.DataFrame(layout_analyses)\n",
    "print(f\"\\nâœ… Layout analysis completed for {len(layout_df)} pages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layout statistics\n",
    "if len(layout_df) > 0:\n",
    "    print(\"=\"*60)\n",
    "    print(\"PAGE LAYOUT ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Region Content Density (9-grid):\")\n",
    "    regions = ['top_left', 'top_center', 'top_right', \n",
    "               'middle_left', 'middle_center', 'middle_right',\n",
    "               'bottom_left', 'bottom_center', 'bottom_right']\n",
    "    for region in regions:\n",
    "        print(f\"   {region:16s}: Mean={layout_df[region].mean():.4f}, Std={layout_df[region].std():.4f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“ Margin Analysis:\")\n",
    "    print(f\"   Top margin density: {layout_df['top_margin_density'].mean():.4f}\")\n",
    "    print(f\"   Bottom margin density: {layout_df['bottom_margin_density'].mean():.4f}\")\n",
    "    print(f\"   Left margin density: {layout_df['left_margin_density'].mean():.4f}\")\n",
    "    print(f\"   Right margin density: {layout_df['right_margin_density'].mean():.4f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“„ Header/Footer:\")\n",
    "    print(f\"   Header density: Mean={layout_df['header_density'].mean():.4f}, Std={layout_df['header_density'].std():.4f}\")\n",
    "    print(f\"   Footer density: Mean={layout_df['footer_density'].mean():.4f}, Std={layout_df['footer_density'].std():.4f}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Content Distribution Variance: {layout_df['content_distribution_variance'].mean():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize layout statistics\n",
    "if len(layout_df) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Region density heatmap (average across all pages)\n",
    "    region_means = [\n",
    "        [layout_df['top_left'].mean(), layout_df['top_center'].mean(), layout_df['top_right'].mean()],\n",
    "        [layout_df['middle_left'].mean(), layout_df['middle_center'].mean(), layout_df['middle_right'].mean()],\n",
    "        [layout_df['bottom_left'].mean(), layout_df['bottom_center'].mean(), layout_df['bottom_right'].mean()]\n",
    "    ]\n",
    "    sns.heatmap(region_means, ax=axes[0, 0], annot=True, fmt='.3f', cmap='YlOrRd',\n",
    "                xticklabels=['Left', 'Center', 'Right'], yticklabels=['Top', 'Middle', 'Bottom'])\n",
    "    axes[0, 0].set_title('Average Content Density by Region', fontweight='bold')\n",
    "    \n",
    "    # Header vs Footer density\n",
    "    axes[0, 1].scatter(layout_df['header_density'], layout_df['footer_density'], alpha=0.3)\n",
    "    axes[0, 1].set_xlabel('Header Density')\n",
    "    axes[0, 1].set_ylabel('Footer Density')\n",
    "    axes[0, 1].set_title('Header vs Footer Density', fontweight='bold')\n",
    "    \n",
    "    # Content distribution variance\n",
    "    axes[1, 0].hist(layout_df['content_distribution_variance'], bins=50, color='purple', edgecolor='black', alpha=0.7)\n",
    "    axes[1, 0].set_xlabel('Content Distribution Variance')\n",
    "    axes[1, 0].set_ylabel('Frequency')\n",
    "    axes[1, 0].set_title('Content Distribution Variance', fontweight='bold')\n",
    "    \n",
    "    # Margin densities comparison\n",
    "    margin_data = {\n",
    "        'Top': layout_df['top_margin_density'].mean(),\n",
    "        'Bottom': layout_df['bottom_margin_density'].mean(),\n",
    "        'Left': layout_df['left_margin_density'].mean(),\n",
    "        'Right': layout_df['right_margin_density'].mean()\n",
    "    }\n",
    "    axes[1, 1].bar(margin_data.keys(), margin_data.values(), color=['red', 'blue', 'green', 'orange'])\n",
    "    axes[1, 1].set_ylabel('Average Density')\n",
    "    axes[1, 1].set_title('Average Margin Densities', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all analysis dataframes\n",
    "if len(page_df) > 0 and len(table_df) > 0 and len(layout_df) > 0:\n",
    "    # Merge on pdf_name and page_num\n",
    "    combined_df = page_df.merge(\n",
    "        table_df, on=['pdf_name', 'page_num'], how='left'\n",
    "    ).merge(\n",
    "        layout_df, on=['pdf_name', 'page_num'], how='left'\n",
    "    )\n",
    "    \n",
    "    print(f\"Combined dataset: {len(combined_df)} pages with {len(combined_df.columns)} features\")\n",
    "    print(f\"\\nColumns: {list(combined_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature correlation matrix\n",
    "if 'combined_df' in dir() and len(combined_df) > 0:\n",
    "    # Select numeric columns for correlation\n",
    "    numeric_cols = combined_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    # Remove columns that might cause issues\n",
    "    cols_to_exclude = ['page_num']\n",
    "    feature_cols = [c for c in numeric_cols if c not in cols_to_exclude]\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = combined_df[feature_cols].corr()\n",
    "    \n",
    "    # Plot correlation heatmap\n",
    "    plt.figure(figsize=(16, 14))\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    sns.heatmap(corr_matrix, mask=mask, annot=False, cmap='RdBu_r', center=0,\n",
    "                square=True, linewidths=0.5)\n",
    "    plt.title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find highly correlated features\n",
    "    print(\"\\nðŸ”— Highly Correlated Feature Pairs (|r| > 0.7):\")\n",
    "    high_corr_pairs = []\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            if abs(corr_matrix.iloc[i, j]) > 0.7:\n",
    "                high_corr_pairs.append((\n",
    "                    corr_matrix.columns[i], \n",
    "                    corr_matrix.columns[j], \n",
    "                    corr_matrix.iloc[i, j]\n",
    "                ))\n",
    "    \n",
    "    high_corr_pairs.sort(key=lambda x: abs(x[2]), reverse=True)\n",
    "    for f1, f2, r in high_corr_pairs[:15]:\n",
    "        print(f\"   {f1} <-> {f2}: r={r:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Page Clustering Analysis (Unsupervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform unsupervised clustering to find natural groupings\n",
    "if 'combined_df' in dir() and len(combined_df) > 0:\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.cluster import KMeans\n",
    "    \n",
    "    # Select features for clustering\n",
    "    cluster_features = [\n",
    "        'edge_density', 'num_lines', 'horizontal_lines', 'vertical_lines',\n",
    "        'white_space_ratio', 'text_density', 'num_contours',\n",
    "        'table_area_ratio', 'h_line_density', 'v_line_density',\n",
    "        'num_intersections', 'structure_ratio',\n",
    "        'header_density', 'footer_density', 'content_distribution_variance',\n",
    "        'middle_center'\n",
    "    ]\n",
    "    \n",
    "    # Filter to available features\n",
    "    available_features = [f for f in cluster_features if f in combined_df.columns]\n",
    "    \n",
    "    # Prepare data\n",
    "    X = combined_df[available_features].fillna(0).values\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # PCA for visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    print(f\"PCA explained variance: {pca.explained_variance_ratio_.sum()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal number of clusters using elbow method\n",
    "if 'X_scaled' in dir():\n",
    "    from sklearn.metrics import silhouette_score\n",
    "    \n",
    "    inertias = []\n",
    "    silhouettes = []\n",
    "    K_range = range(2, 11)\n",
    "    \n",
    "    for k in K_range:\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        kmeans.fit(X_scaled)\n",
    "        inertias.append(kmeans.inertia_)\n",
    "        silhouettes.append(silhouette_score(X_scaled, kmeans.labels_))\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Elbow plot\n",
    "    axes[0].plot(K_range, inertias, 'bo-')\n",
    "    axes[0].set_xlabel('Number of Clusters (k)')\n",
    "    axes[0].set_ylabel('Inertia')\n",
    "    axes[0].set_title('Elbow Method for Optimal k', fontweight='bold')\n",
    "    \n",
    "    # Silhouette plot\n",
    "    axes[1].plot(K_range, silhouettes, 'go-')\n",
    "    axes[1].set_xlabel('Number of Clusters (k)')\n",
    "    axes[1].set_ylabel('Silhouette Score')\n",
    "    axes[1].set_title('Silhouette Score vs k', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Best k based on silhouette\n",
    "    best_k = K_range[np.argmax(silhouettes)]\n",
    "    print(f\"\\nðŸ“Š Best k based on silhouette score: {best_k}\")\n",
    "    print(f\"Note: We have 5 target classes, but natural clusters may differ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster with k=5 (matching our target classes)\n",
    "if 'X_scaled' in dir():\n",
    "    kmeans_5 = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans_5.fit_predict(X_scaled)\n",
    "    \n",
    "    combined_df['cluster'] = cluster_labels\n",
    "    \n",
    "    # Visualize clusters in PCA space\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=cluster_labels, cmap='viridis', alpha=0.6)\n",
    "    plt.colorbar(scatter, label='Cluster')\n",
    "    plt.xlabel('First Principal Component')\n",
    "    plt.ylabel('Second Principal Component')\n",
    "    plt.title('Page Clusters in PCA Space (k=5)', fontsize=14, fontweight='bold')\n",
    "    plt.show()\n",
    "    \n",
    "    # Cluster distribution\n",
    "    print(\"\\nðŸ“Š Cluster Distribution:\")\n",
    "    cluster_counts = combined_df['cluster'].value_counts().sort_index()\n",
    "    for cluster, count in cluster_counts.items():\n",
    "        print(f\"   Cluster {cluster}: {count} pages ({count/len(combined_df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cluster characteristics\n",
    "if 'combined_df' in dir() and 'cluster' in combined_df.columns:\n",
    "    print(\"\\nðŸ“‹ Cluster Characteristics:\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    key_features = ['edge_density', 'num_lines', 'has_table_combined', 'table_area_ratio',\n",
    "                    'white_space_ratio', 'text_density', 'header_density']\n",
    "    \n",
    "    available_key_features = [f for f in key_features if f in combined_df.columns]\n",
    "    \n",
    "    cluster_summary = combined_df.groupby('cluster')[available_key_features].mean()\n",
    "    display(cluster_summary.round(4))\n",
    "    \n",
    "    # Visualize cluster characteristics\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, feature in enumerate(available_key_features[:6]):\n",
    "        cluster_means = combined_df.groupby('cluster')[feature].mean()\n",
    "        axes[idx].bar(cluster_means.index, cluster_means.values, \n",
    "                      color=plt.cm.viridis(np.linspace(0, 1, 5)))\n",
    "        axes[idx].set_xlabel('Cluster')\n",
    "        axes[idx].set_ylabel(feature)\n",
    "        axes[idx].set_title(f'{feature} by Cluster', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Sample Pages from Each Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cluster_samples(combined_df: pd.DataFrame, n_samples_per_cluster: int = 3):\n",
    "    \"\"\"\n",
    "    Display sample pages from each cluster.\n",
    "    \n",
    "    Args:\n",
    "        combined_df: DataFrame with cluster assignments\n",
    "        n_samples_per_cluster: Number of samples to show per cluster\n",
    "    \"\"\"\n",
    "    n_clusters = combined_df['cluster'].nunique()\n",
    "    \n",
    "    fig, axes = plt.subplots(n_clusters, n_samples_per_cluster, \n",
    "                             figsize=(5*n_samples_per_cluster, 6*n_clusters))\n",
    "    \n",
    "    for cluster_idx in range(n_clusters):\n",
    "        cluster_pages = combined_df[combined_df['cluster'] == cluster_idx]\n",
    "        samples = cluster_pages.sample(n=min(n_samples_per_cluster, len(cluster_pages)), random_state=42)\n",
    "        \n",
    "        for sample_idx, (_, row) in enumerate(samples.iterrows()):\n",
    "            pdf_path = row['pdf_path']\n",
    "            page_num = int(row['page_num'])\n",
    "            \n",
    "            # Extract the specific page\n",
    "            images = extract_pages_as_images(pdf_path, dpi=100, max_pages=page_num)\n",
    "            if images and len(images) >= page_num:\n",
    "                img = images[page_num - 1]\n",
    "                \n",
    "                ax = axes[cluster_idx, sample_idx] if n_clusters > 1 else axes[sample_idx]\n",
    "                ax.imshow(img)\n",
    "                ax.set_title(f\"Cluster {cluster_idx}\\n{row['pdf_name']}\\nPage {page_num}\", fontsize=9)\n",
    "                ax.axis('off')\n",
    "    \n",
    "    plt.suptitle('Sample Pages from Each Cluster', fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show samples from each cluster\n",
    "if 'combined_df' in dir() and 'cluster' in combined_df.columns and 'pdf_path' in combined_df.columns:\n",
    "    print(\"Displaying sample pages from each cluster...\")\n",
    "    show_cluster_samples(combined_df, n_samples_per_cluster=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. EDA Summary & Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"                    EDA SUMMARY & KEY INSIGHTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if 'pdf_df' in dir() and len(pdf_df) > 0:\n",
    "    print(f\"\\nðŸ“ DATASET OVERVIEW\")\n",
    "    print(f\"   Total PDF documents: {len(pdf_df)}\")\n",
    "    print(f\"   Total pages: {pdf_df['num_pages'].sum():,}\")\n",
    "    print(f\"   Average pages per document: {pdf_df['num_pages'].mean():.1f}\")\n",
    "    print(f\"   Total dataset size: {pdf_df['file_size_mb'].sum():.2f} MB\")\n",
    "\n",
    "if 'page_df' in dir() and len(page_df) > 0:\n",
    "    print(f\"\\nðŸ“Š PAGE IMAGE STATISTICS\")\n",
    "    print(f\"   Average dimensions: {page_df['width'].mean():.0f} x {page_df['height'].mean():.0f} pixels\")\n",
    "    print(f\"   Aspect ratio range: {page_df['aspect_ratio'].min():.3f} - {page_df['aspect_ratio'].max():.3f}\")\n",
    "    print(f\"   Average edge density: {page_df['edge_density'].mean():.4f}\")\n",
    "    print(f\"   Average text density: {page_df['text_density'].mean():.4f}\")\n",
    "\n",
    "if 'table_df' in dir() and len(table_df) > 0:\n",
    "    pages_with_tables = table_df['has_table_combined'].sum() if 'has_table_combined' in table_df.columns else 0\n",
    "    print(f\"\\nðŸ“‹ TABLE DETECTION\")\n",
    "    print(f\"   Pages with tables: {pages_with_tables} ({pages_with_tables/len(table_df)*100:.1f}%)\")\n",
    "    print(f\"   Pages without tables: {len(table_df) - pages_with_tables} ({(len(table_df) - pages_with_tables)/len(table_df)*100:.1f}%)\")\n",
    "\n",
    "if 'combined_df' in dir() and 'cluster' in combined_df.columns:\n",
    "    print(f\"\\nðŸ”¬ UNSUPERVISED CLUSTERING (k=5)\")\n",
    "    cluster_counts = combined_df['cluster'].value_counts().sort_index()\n",
    "    for cluster, count in cluster_counts.items():\n",
    "        print(f\"   Cluster {cluster}: {count} pages ({count/len(combined_df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nðŸŽ¯ KEY OBSERVATIONS FOR CLASSIFICATION\")\n",
    "print(\"   1. Table detection can help distinguish Tabular vs Text notes\")\n",
    "print(\"   2. Edge density and line counts correlate with structured content\")\n",
    "print(\"   3. Layout region analysis can identify headers/titles\")\n",
    "print(\"   4. White space ratio varies between document types\")\n",
    "print(\"   5. Unsupervised clustering shows natural page groupings\")\n",
    "\n",
    "print(f\"\\nðŸ’¡ RECOMMENDATIONS FOR MODELING\")\n",
    "print(\"   1. Use CNN-based model for visual features (ResNet, EfficientNet)\")\n",
    "print(\"   2. Table detection features should be included\")\n",
    "print(\"   3. Consider data augmentation for class imbalance\")\n",
    "print(\"   4. Multi-scale features may help capture layout patterns\")\n",
    "print(\"   5. Ensemble approach combining visual + structural features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save analysis results\n",
    "if 'combined_df' in dir():\n",
    "    # Save to CSV for later use\n",
    "    combined_df.to_csv('page_analysis_results.csv', index=False)\n",
    "    print(\"\\nðŸ’¾ Analysis results saved to 'page_analysis_results.csv'\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    summary_stats = combined_df.describe()\n",
    "    summary_stats.to_csv('page_analysis_summary.csv')\n",
    "    print(\"ðŸ’¾ Summary statistics saved to 'page_analysis_summary.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 13. Check for Labels/Annotations (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any label/annotation files in the dataset\n",
    "def find_label_files(root_path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for potential label/annotation files.\n",
    "    \n",
    "    Args:\n",
    "        root_path: Root directory to search\n",
    "    \n",
    "    Returns:\n",
    "        List of potential label file paths\n",
    "    \"\"\"\n",
    "    label_patterns = ['label', 'annotation', 'class', 'target', 'ground_truth', 'gt']\n",
    "    label_extensions = ['.csv', '.json', '.txt', '.xlsx', '.xml']\n",
    "    \n",
    "    found_files = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(root_path):\n",
    "        for file in files:\n",
    "            file_lower = file.lower()\n",
    "            if any(ext in file_lower for ext in label_extensions):\n",
    "                if any(pattern in file_lower for pattern in label_patterns):\n",
    "                    found_files.append(os.path.join(root, file))\n",
    "                elif file_lower.endswith('.csv') or file_lower.endswith('.json'):\n",
    "                    # Also check generic CSV/JSON files\n",
    "                    found_files.append(os.path.join(root, file))\n",
    "    \n",
    "    return found_files\n",
    "\n",
    "# Search for label files\n",
    "if os.path.exists(DATA_PATH):\n",
    "    label_files = find_label_files(DATA_PATH)\n",
    "    \n",
    "    if label_files:\n",
    "        print(\"ðŸ“‹ Potential label/annotation files found:\")\n",
    "        for f in label_files:\n",
    "            print(f\"   - {f}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ No label/annotation files found in the dataset.\")\n",
    "        print(\"   You may need to create labels manually or use the unsupervised clusters as a starting point.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If labels exist, load and analyze them\n",
    "# Uncomment and modify the path when you have labels\n",
    "\n",
    "# LABELS_PATH = \"path/to/your/labels.csv\"  # Update this\n",
    "\n",
    "# if os.path.exists(LABELS_PATH):\n",
    "#     labels_df = pd.read_csv(LABELS_PATH)\n",
    "#     print(f\"Labels loaded: {len(labels_df)} entries\")\n",
    "#     print(f\"\\nLabel distribution:\")\n",
    "#     print(labels_df['label'].value_counts())\n",
    "    \n",
    "#     # Visualize class distribution\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     labels_df['label'].value_counts().plot(kind='bar')\n",
    "#     plt.title('Class Distribution')\n",
    "#     plt.xlabel('Class')\n",
    "#     plt.ylabel('Count')\n",
    "#     plt.xticks(rotation=45)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Next Steps\n",
    "\n",
    "Based on this EDA, the next phase should include:\n",
    "\n",
    "1. **Data Preprocessing**:\n",
    "   - Convert all PDFs to images at consistent resolution\n",
    "   - Resize/normalize images for model input\n",
    "   - Apply any necessary image enhancements\n",
    "\n",
    "2. **Labeling** (if not already done):\n",
    "   - Create labels for the 5 classes\n",
    "   - Use cluster analysis as a starting point for semi-supervised labeling\n",
    "\n",
    "3. **Feature Engineering**:\n",
    "   - Extract table detection features\n",
    "   - Layout features (region densities, margins)\n",
    "   - Edge/line features\n",
    "\n",
    "4. **Model Development**:\n",
    "   - CNN-based visual classification (ResNet, EfficientNet)\n",
    "   - Consider incorporating structural features\n",
    "   - Handle class imbalance if present"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
